{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Reference\n* https://www.kaggle.com/code/yasufuminakama/pppm-deberta-v3-large-baseline-w-w-b-train\n* https://www.kaggle.com/code/debarshichanda/pytorch-feedback-deberta-v3-baseline","metadata":{}},{"cell_type":"markdown","source":"# Library","metadata":{"id":"xYtxXXZskkqL"}},{"cell_type":"code","source":"import os\nimport gc\nimport math\nimport time\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.simplefilter('ignore')\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\n\nfrom transformers import AutoModel, AutoConfig, AutoTokenizer, AdamW, DataCollatorWithPadding\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"Ya4TlC2bj49v","execution":{"iopub.status.busy":"2022-06-28T03:04:24.949089Z","iopub.execute_input":"2022-06-28T03:04:24.949999Z","iopub.status.idle":"2022-06-28T03:04:33.018257Z","shell.execute_reply.started":"2022-06-28T03:04:24.949881Z","shell.execute_reply":"2022-06-28T03:04:33.017272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Directly Setting","metadata":{"id":"A-4smcVJm70R"}},{"cell_type":"code","source":"INPUT_DIR = '../input/feedback-price-datasets-with-essay-text/'\nOUTPUT_DIR = './baseline/'\n\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"id":"Cje9GuEqknrV","execution":{"iopub.status.busy":"2022-06-28T03:04:33.022267Z","iopub.execute_input":"2022-06-28T03:04:33.02449Z","iopub.status.idle":"2022-06-28T03:04:33.029341Z","shell.execute_reply.started":"2022-06-28T03:04:33.024457Z","shell.execute_reply":"2022-06-28T03:04:33.028387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CFG","metadata":{"id":"xL12cAi9nZoi"}},{"cell_type":"code","source":"class CFG:\n    wandb = False\n    apex = True\n    model = 'microsoft/deberta-v3-base'\n    seed = 42\n    n_splits = 4\n    max_len = 512\n    dropout = 0.2\n    target_size=3\n    n_accumulate=1\n    print_freq = 100\n    min_lr=1e-6\n    scheduler = 'cosine'\n    batch_size = 8\n    num_workers = 3\n    lr = 2e-5\n    weigth_decay = 0.01\n    epochs = 4\n    n_fold = 4\n    trn_fold = [0, 1, 2, 3]\n    train = True \n    num_warmup_steps = 0\n    num_cycles=0.5\n    debug = True\n    debug_ver2 = False\n\nif CFG.debug:\n    CFG.epochs = 2\n    CFG.trn_fold = [0, 1]\n    CFG.print_freq = 10\n    \nif CFG.debug_ver2:\n    CFG.epochs = 1\n    CFG.trn_fold = [0, 1]","metadata":{"id":"x4uFDjQtnSv2","execution":{"iopub.status.busy":"2022-06-28T03:04:33.030872Z","iopub.execute_input":"2022-06-28T03:04:33.031364Z","iopub.status.idle":"2022-06-28T03:04:33.040833Z","shell.execute_reply.started":"2022-06-28T03:04:33.031327Z","shell.execute_reply":"2022-06-28T03:04:33.039871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{"id":"mroSLHTSoEDD"}},{"cell_type":"code","source":"def criterion(outputs, labels):\n    return nn.CrossEntropyLoss()(outputs, labels)\n\"\"\"\ndef get_score(outputs, labels):\n    return log_loss(labels, outputs)\n\"\"\"\ndef get_score(outputs, labels):\n    outputs = F.softmax(torch.tensor(outputs)).numpy()\n    return log_loss(labels, outputs)\n\ndef get_logger(filename=OUTPUT_DIR+'train'):\n    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()\n\ndef seed_everything(seed=CFG.seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","metadata":{"id":"22QfER6_oA36","execution":{"iopub.status.busy":"2022-06-28T03:04:33.043485Z","iopub.execute_input":"2022-06-28T03:04:33.04394Z","iopub.status.idle":"2022-06-28T03:04:33.056903Z","shell.execute_reply.started":"2022-06-28T03:04:33.043903Z","shell.execute_reply":"2022-06-28T03:04:33.056015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DataLoading","metadata":{"id":"XNus9zL6pgzX"}},{"cell_type":"code","source":"train = pd.read_csv(INPUT_DIR+'train_all.csv')\ntest = pd.read_csv(INPUT_DIR+'test_all.csv')\ndisplay(train.head())\nprint(train.shape)\ndisplay(test.head())\nprint(test.shape)","metadata":{"id":"BXXsbnL5oYhE","outputId":"6a8a6704-8ba0-4615-af83-fc1779fb3b44","execution":{"iopub.status.busy":"2022-06-28T03:04:33.058224Z","iopub.execute_input":"2022-06-28T03:04:33.059272Z","iopub.status.idle":"2022-06-28T03:04:34.757875Z","shell.execute_reply.started":"2022-06-28T03:04:33.059235Z","shell.execute_reply":"2022-06-28T03:04:34.756941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CV splits","metadata":{"id":"pscUPoFbqA-Y"}},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=CFG.n_splits, shuffle=True, random_state=CFG.seed)\ntrain['fold'] = -1\ntrain['label'] = train['discourse_effectiveness'].map({'Ineffective':0, 'Adequate':1, 'Effective':2})\nfor i, (_, val_) in enumerate(skf.split(train, train['label'])):\n    train.loc[val_, 'fold'] = int(i)\ntrain.fold.value_counts()","metadata":{"id":"hvdEmWvIp0w2","outputId":"6170b341-5a3d-41cd-c744-fc26ca740b4e","execution":{"iopub.status.busy":"2022-06-28T03:04:34.759217Z","iopub.execute_input":"2022-06-28T03:04:34.760156Z","iopub.status.idle":"2022-06-28T03:04:34.798811Z","shell.execute_reply.started":"2022-06-28T03:04:34.760117Z","shell.execute_reply":"2022-06-28T03:04:34.797877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.debug:\n    display(train.groupby('fold').size())\n    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n    display(train.groupby('fold').size())","metadata":{"id":"uLbJRV3BVa9c","outputId":"b59faa48-6fa6-4ea9-d6cd-3b170006f9be","execution":{"iopub.status.busy":"2022-06-28T03:04:34.80102Z","iopub.execute_input":"2022-06-28T03:04:34.801758Z","iopub.status.idle":"2022-06-28T03:04:34.822622Z","shell.execute_reply.started":"2022-06-28T03:04:34.801721Z","shell.execute_reply":"2022-06-28T03:04:34.82143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# tokenizer","metadata":{"id":"JnEn0nxGsMYv"}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(CFG.model)\ntokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\nCFG.tokenizer = tokenizer","metadata":{"id":"ZdkPCUQ8sNuK","outputId":"854093bb-f761-4db0-be4f-026228ecbe06","execution":{"iopub.status.busy":"2022-06-28T03:04:34.824245Z","iopub.execute_input":"2022-06-28T03:04:34.82459Z","iopub.status.idle":"2022-06-28T03:04:39.342932Z","shell.execute_reply.started":"2022-06-28T03:04:34.824555Z","shell.execute_reply":"2022-06-28T03:04:39.342005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"wbpEr44xrTVT"}},{"cell_type":"code","source":"train['text'] = train['discourse_text'] + '[SEP]' + train['essay_text']\n\nclass FeedBackDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length):\n        self.df = df\n        self.max_len = CFG.max_len\n        self.text = df['text'].values\n        self.tokenizer = CFG.tokenizer\n        self.targets = df['label'].values\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = tokenizer.encode_plus(\n            text,\n            truncation=True,\n            add_special_tokens=True,\n            max_length = self.max_len\n        )\n        return {\n            'input_ids':inputs['input_ids'],\n            'attention_mask':inputs['attention_mask'],\n            'target':self.targets[index]\n            }","metadata":{"id":"sNc112XfrUzr","execution":{"iopub.status.busy":"2022-06-28T03:04:39.344327Z","iopub.execute_input":"2022-06-28T03:04:39.344792Z","iopub.status.idle":"2022-06-28T03:04:39.357244Z","shell.execute_reply.started":"2022-06-28T03:04:39.34475Z","shell.execute_reply":"2022-06-28T03:04:39.356338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"collate_fn = DataCollatorWithPadding(tokenizer=CFG.tokenizer)","metadata":{"id":"0jlVDmK_tsQU","execution":{"iopub.status.busy":"2022-06-28T03:04:39.361226Z","iopub.execute_input":"2022-06-28T03:04:39.361482Z","iopub.status.idle":"2022-06-28T03:04:39.370728Z","shell.execute_reply.started":"2022-06-28T03:04:39.361459Z","shell.execute_reply":"2022-06-28T03:04:39.369776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"lnLeAsdevBkW"}},{"cell_type":"code","source":"class MeanPooling(nn.Module):\n    def __init__(self):\n        super(MeanPooling, self).__init__()\n        \n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        return mean_embeddings","metadata":{"execution":{"iopub.status.busy":"2022-06-28T03:04:39.372256Z","iopub.execute_input":"2022-06-28T03:04:39.372913Z","iopub.status.idle":"2022-06-28T03:04:39.381616Z","shell.execute_reply.started":"2022-06-28T03:04:39.372877Z","shell.execute_reply":"2022-06-28T03:04:39.380705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FeedBackModel(nn.Module):\n    def __init__(self, model_name):\n        super(FeedBackModel, self).__init__()\n        self.model = AutoModel.from_pretrained(model_name)\n        self.config = AutoConfig.from_pretrained(model_name)\n        self.drop = nn.Dropout(p=0.2)\n        self.pooler = MeanPooling()\n        self.fc = nn.Linear(self.config.hidden_size, CFG.target_size)\n        \n    def forward(self, ids, mask):        \n        out = self.model(input_ids=ids, \n                         attention_mask=mask,\n                         output_hidden_states=False)\n        out = self.pooler(out.last_hidden_state, mask)\n        out = self.drop(out)\n        outputs = self.fc(out)\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2022-06-28T03:04:39.383095Z","iopub.execute_input":"2022-06-28T03:04:39.383744Z","iopub.status.idle":"2022-06-28T03:04:39.392794Z","shell.execute_reply.started":"2022-06-28T03:04:39.383698Z","shell.execute_reply":"2022-06-28T03:04:39.391846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# HelperFunction","metadata":{"id":"Grcdpuaxxfwn"}},{"cell_type":"code","source":"def asMinutes(s):\n    m = math.floor(s/60)\n    s -= m * 60\n    return \"%dm %ds\" % (m, s)\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n\ndef get_scheduler(cfg, optimizer, num_train_steps):\n    if cfg.scheduler == 'linear':\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n        )\n    elif cfg.scheduler == 'cosine':\n        scheduler = get_cosine_schedule_with_warmup(\n            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n        )\n    return scheduler\n\ndef train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n    model.train()\n\n    dataset_size = 0\n    running_loss = 0\n\n    start = end = time.time()\n\n    for step, data in enumerate(dataloader):\n        ids = data['input_ids'].to(device, dtype=torch.long)\n        mask = data['attention_mask'].to(device, dtype=torch.long)\n        targets = data['target'].to(device, dtype=torch.long)\n\n        batch_size = ids.size(0)\n        \n        outputs = model(ids, mask)\n        loss = criterion(outputs, targets)\n\n        #accumulate\n        loss = loss / CFG.n_accumulate \n        loss.backward()\n        if (step +1) % CFG.n_accumulate == 0:\n            optimizer.step()\n\n            optimizer.zero_grad()\n            if scheduler is not None:\n                scheduler.step()\n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n\n        epoch_loss = running_loss / dataset_size\n\n        end = time.time()\n        \n        if step % CFG.print_freq == 0 or step == (len(dataloader)-1):\n            print('Epoch: [{0}][{1}/{2}] '\n                  'Elapsed {remain:s} '\n                  .format(epoch+1, step, len(dataloader), \n                          remain=timeSince(start, float(step+1)/len(dataloader))))\n\n    gc.collect()\n\n    return epoch_loss\n\n\n@torch.no_grad()\ndef valid_one_epoch(model, dataloader, device, epoch):\n    model.eval()\n\n    dataset_size = 0\n    running_loss = 0\n\n    start = end = time.time()\n    pred = []\n\n    for step, data in enumerate(dataloader):\n        ids = data['input_ids'].to(device, dtype=torch.long)\n        mask = data['attention_mask'].to(device, dtype=torch.long)\n        targets = data['target'].to(device, dtype=torch.long)\n\n        batch_size = ids.size(0)\n        outputs = model(ids, mask)\n        loss = criterion(outputs, targets)\n        pred.append(outputs.to('cpu').numpy())\n\n        running_loss += (loss.item()* batch_size)\n        dataset_size += batch_size\n\n        epoch_loss = running_loss / dataset_size\n\n        end = time.time()\n\n        if step % CFG.print_freq == 0 or step == (len(dataloader)-1):\n            print('EVAL: [{0}/{1}] '\n                  'Elapsed {remain:s} '\n                  .format(step, len(dataloader),\n                          remain=timeSince(start, float(step+1)/len(dataloader))))\n            \n    pred = np.concatenate(pred)\n            \n    return epoch_loss, pred","metadata":{"id":"ZYhch_bfxbrn","execution":{"iopub.status.busy":"2022-06-28T03:04:39.394385Z","iopub.execute_input":"2022-06-28T03:04:39.395019Z","iopub.status.idle":"2022-06-28T03:04:39.418865Z","shell.execute_reply.started":"2022-06-28T03:04:39.394985Z","shell.execute_reply":"2022-06-28T03:04:39.418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_loop(fold):\n    #wandb.watch(model, log_freq=100)\n\n    LOGGER.info(f'-------------fold:{fold} training-------------')\n\n    train_data = train[train.fold != fold].reset_index(drop=True)\n    valid_data = train[train.fold == fold].reset_index(drop=True)\n    valid_labels = valid_data.label.values\n\n    trainDataset = FeedBackDataset(train_data, CFG.tokenizer, CFG.max_len)\n    validDataset = FeedBackDataset(valid_data, CFG.tokenizer, CFG.max_len)\n\n    train_loader = DataLoader(trainDataset,\n                              batch_size = CFG.batch_size,\n                              shuffle=True,\n                              collate_fn = collate_fn,\n                              num_workers = CFG.num_workers,\n                              pin_memory = True,\n                              drop_last=True)\n    \n    valid_loader = DataLoader(validDataset,\n                              batch_size = CFG.batch_size,\n                              shuffle=False,\n                              collate_fn = collate_fn,\n                              num_workers = CFG.num_workers,\n                              pin_memory = True,\n                              drop_last=False)\n    \n    model = FeedBackModel(CFG.model)\n    torch.save(model.config, OUTPUT_DIR+'config.pth')\n    model.to(device)\n    optimizer = AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weigth_decay)\n    num_train_steps = int(len(train_data) / CFG.batch_size * CFG.epochs)\n    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n\n    # loop\n    best_score = 100\n\n    for epoch in range(CFG.epochs):\n        start_time = time.time()\n\n        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, train_loader, device, epoch)\n        valid_epoch_loss, pred = valid_one_epoch(model, valid_loader, device, epoch)\n\n        score = get_score(pred, valid_labels)\n\n        elapsed = time.time() - start_time\n\n        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {train_epoch_loss:.4f}  avg_val_loss: {valid_epoch_loss:.4f}  time: {elapsed:.0f}s')\n        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n        if CFG.wandb:\n            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n                       f\"[fold{fold}] avg_train_loss\": train_epoch_loss, \n                       f\"[fold{fold}] avg_val_loss\": valid_epoch_loss,\n                       f\"[fold{fold}] score\": score})\n            \n        if score < best_score:\n            best_score = score\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            torch.save({'model': model.state_dict(),\n                        'predictions': pred},\n                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n            \n    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n                             map_location=torch.device('cpu'))['predictions']\n    valid_data['pred_0'] = predictions[:, 0]\n    valid_data['pred_1'] = predictions[:, 1]\n    valid_data['pred_2'] = predictions[:, 2]\n\n\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    return valid_data","metadata":{"id":"ZUzLb00i5_ku","execution":{"iopub.status.busy":"2022-06-28T03:04:39.421029Z","iopub.execute_input":"2022-06-28T03:04:39.421719Z","iopub.status.idle":"2022-06-28T03:04:39.43924Z","shell.execute_reply.started":"2022-06-28T03:04:39.421683Z","shell.execute_reply":"2022-06-28T03:04:39.438291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{"id":"seicsQO4c6ku"}},{"cell_type":"code","source":"if __name__ == '__main__':\n    \n    def get_result(oof_df):\n        labels = oof_df['label'].values\n        preds = oof_df[['pred_0', 'pred_1', 'pred_2']].values.tolist()\n        score = get_score(preds, labels)\n        LOGGER.info(f'Score: {score:<.4f}')\n    \n    if CFG.train:\n        oof_df = pd.DataFrame()\n        for fold in range(CFG.n_fold):\n            if fold in CFG.trn_fold:\n                _oof_df = train_loop(fold)\n                oof_df = pd.concat([oof_df, _oof_df])\n                LOGGER.info(f\"========== fold: {fold} result ==========\")\n                get_result(_oof_df)\n        oof_df = oof_df.reset_index(drop=True)\n        LOGGER.info(f\"========== CV ==========\")\n        get_result(oof_df)\n        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n        oof_df.to_csv(OUTPUT_DIR+f'oof_df.csv', index=False)\n        \n    if CFG.wandb:\n        wandb.finish()","metadata":{"id":"4hZES1xFHaWl","outputId":"ab87e3b8-8451-402c-9a71-82465a00f9b9","execution":{"iopub.status.busy":"2022-06-28T03:04:39.442083Z","iopub.execute_input":"2022-06-28T03:04:39.442588Z","iopub.status.idle":"2022-06-28T03:06:27.960168Z","shell.execute_reply.started":"2022-06-28T03:04:39.44256Z","shell.execute_reply":"2022-06-28T03:06:27.958569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"A = pd.read_csv(OUTPUT_DIR+'oof_df.csv')\nA.head()","metadata":{"id":"9MA3sGrie_NH","outputId":"b727fe90-4c90-4b63-aed1-a337a8d6990b","execution":{"iopub.status.busy":"2022-06-28T03:06:27.961664Z","iopub.status.idle":"2022-06-28T03:06:27.962402Z","shell.execute_reply.started":"2022-06-28T03:06:27.962138Z","shell.execute_reply":"2022-06-28T03:06:27.962163Z"},"trusted":true},"execution_count":null,"outputs":[]}]}